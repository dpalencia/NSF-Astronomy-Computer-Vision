{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "attended-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing / Demonstrating the use of marsvision modules to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abandoned-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marsvision.pipeline import Model\n",
    "from marsvision.vision import ModelDefinitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "geographic-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dpale/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "alex_model = ModelDefinitions.alexnet()\n",
    "model = Model(alex_model, \"pytorch\", \n",
    "              dataset_root_directory=r\"C:\\Users\\dpale\\Desktop\\Projects\\marsvision\\test\\deep_mars_test_data\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "growing-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/4\n",
      "----------\n",
      "Running loss: 114.4535140991211 | Running corrects: 0\n",
      "Running loss: 452.7767562866211 | Running corrects: 1\n",
      "Running loss: 1330.0981674194336 | Running corrects: 3\n",
      "Running loss: 4219.426292419434 | Running corrects: 5\n",
      "Running loss: 4284.65291595459 | Running corrects: 5\n",
      "17\n",
      "train loss: 252.0384 Acc: 0.2941 | Images trained on: 17\n",
      "Running loss: 0.0 | Running corrects: 1\n",
      "1\n",
      "val loss: 0.0000 Acc: 1.0000 | Images trained on: 1\n",
      "Epoch: 1/4\n",
      "----------\n",
      "Running loss: 378.1729736328125 | Running corrects: 3\n",
      "Running loss: 1216.1259765625 | Running corrects: 5\n",
      "Running loss: 2158.2842407226562 | Running corrects: 5\n",
      "Running loss: 2581.27294921875 | Running corrects: 7\n",
      "Running loss: 2581.27294921875 | Running corrects: 8\n",
      "17\n",
      "train loss: 151.8396 Acc: 0.4706 | Images trained on: 17\n",
      "Running loss: 0.0 | Running corrects: 1\n",
      "1\n",
      "val loss: 0.0000 Acc: 1.0000 | Images trained on: 1\n",
      "Epoch: 2/4\n",
      "----------\n",
      "Running loss: 326.4542541503906 | Running corrects: 3\n",
      "Running loss: 944.2181091308594 | Running corrects: 5\n",
      "Running loss: 1912.6961975097656 | Running corrects: 5\n",
      "Running loss: 2104.1873626708984 | Running corrects: 8\n",
      "Running loss: 2104.1873626708984 | Running corrects: 9\n",
      "17\n",
      "train loss: 123.7757 Acc: 0.5294 | Images trained on: 17\n",
      "Running loss: 0.0 | Running corrects: 1\n",
      "1\n",
      "val loss: 0.0000 Acc: 1.0000 | Images trained on: 1\n",
      "Epoch: 3/4\n",
      "----------\n",
      "Running loss: 447.84942626953125 | Running corrects: 3\n",
      "Running loss: 1208.4041137695312 | Running corrects: 5\n",
      "Running loss: 2155.3046264648438 | Running corrects: 5\n",
      "Running loss: 2350.169952392578 | Running corrects: 7\n",
      "Running loss: 2350.169952392578 | Running corrects: 8\n",
      "17\n",
      "train loss: 138.2453 Acc: 0.4706 | Images trained on: 17\n",
      "Running loss: 0.0 | Running corrects: 1\n",
      "1\n",
      "val loss: 0.0000 Acc: 1.0000 | Images trained on: 1\n",
      "Epoch: 4/4\n",
      "----------\n",
      "Running loss: 301.6221618652344 | Running corrects: 3\n",
      "Running loss: 863.4434509277344 | Running corrects: 5\n",
      "Running loss: 1832.1299743652344 | Running corrects: 5\n",
      "Running loss: 2098.394317626953 | Running corrects: 7\n",
      "Running loss: 2098.394317626953 | Running corrects: 8\n",
      "17\n",
      "train loss: 123.4350 Acc: 0.4706 | Images trained on: 17\n",
      "Running loss: 0.0 | Running corrects: 1\n",
      "1\n",
      "val loss: 0.0000 Acc: 1.0000 | Images trained on: 1\n",
      "Best Epoch Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "yellow-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marsvision.utilities import DataUtility\n",
    "data_utility = DataUtility(r\"C:\\Users\\dpale\\Desktop\\Projects\\marsvision\\test\\deep_mars_test_data\\map-proj\")\n",
    "data_utility.data_reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "taken-housing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22, 3, 227, 227])\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(data_utility.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "polar-account",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-framing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
