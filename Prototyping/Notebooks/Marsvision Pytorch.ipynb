{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attended-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing / Demonstrating the use of marsvision modules to train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abandoned-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marsvision.pipeline import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "geographic-settlement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\dpale/.cache\\torch\\hub\\pytorch_vision_v0.6.0\n",
      "c:\\users\\dpale\\desktop\\projects\\marsvision\\marsvision\\pipeline\\Model.py:51: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  self.config = yaml.load(yaml_cfg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "alex_model = torch.hub.load('pytorch/vision:v0.6.0', 'alexnet', pretrained=True)\n",
    "model = Model(alex_model, \"pytorch\", \n",
    "              dataset_root_directory=r\"C:\\Users\\dpale\\Desktop\\Projects\\marsvision\\test\\deep_mars_test_data\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "growing-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/4\n",
      "----------\n",
      "Running loss: 1514.2755126953125 | Running corrects: 0\n",
      "Running loss: 8944.213989257812 | Running corrects: 0\n",
      "Running loss: 75305.75305175781 | Running corrects: 0\n",
      "Running loss: 888353.8780517578 | Running corrects: 2\n",
      "Running loss: 13150325.878051758 | Running corrects: 2\n",
      "17\n",
      "train loss: 773548.5811 Acc: 0.1176 | Images trained on: 17\n",
      "Running loss: 0.0 | Running corrects: 1\n",
      "1\n",
      "val loss: 0.0000 Acc: 1.0000 | Images trained on: 1\n",
      "Epoch: 1/4\n",
      "----------\n",
      "Running loss: 1681991936.0 | Running corrects: 1\n",
      "Running loss: 3.107107176973048e+17 | Running corrects: 2\n",
      "Running loss: nan | Running corrects: 4\n",
      "Running loss: nan | Running corrects: 6\n",
      "Running loss: nan | Running corrects: 6\n",
      "17\n",
      "train loss: nan Acc: 0.3529 | Images trained on: 17\n",
      "Running loss: nan | Running corrects: 0\n",
      "1\n",
      "val loss: nan Acc: 0.0000 | Images trained on: 1\n",
      "Epoch: 2/4\n",
      "----------\n",
      "Running loss: nan | Running corrects: 2\n",
      "Running loss: nan | Running corrects: 3\n",
      "Running loss: nan | Running corrects: 5\n",
      "Running loss: nan | Running corrects: 7\n",
      "Running loss: nan | Running corrects: 7\n",
      "17\n",
      "train loss: nan Acc: 0.4118 | Images trained on: 17\n",
      "Running loss: nan | Running corrects: 0\n",
      "1\n",
      "val loss: nan Acc: 0.0000 | Images trained on: 1\n",
      "Epoch: 3/4\n",
      "----------\n",
      "Running loss: nan | Running corrects: 2\n",
      "Running loss: nan | Running corrects: 3\n",
      "Running loss: nan | Running corrects: 5\n",
      "Running loss: nan | Running corrects: 7\n",
      "Running loss: nan | Running corrects: 7\n",
      "17\n",
      "train loss: nan Acc: 0.4118 | Images trained on: 17\n",
      "Running loss: nan | Running corrects: 0\n",
      "1\n",
      "val loss: nan Acc: 0.0000 | Images trained on: 1\n",
      "Epoch: 4/4\n",
      "----------\n",
      "Running loss: nan | Running corrects: 2\n",
      "Running loss: nan | Running corrects: 3\n",
      "Running loss: nan | Running corrects: 5\n",
      "Running loss: nan | Running corrects: 7\n",
      "Running loss: nan | Running corrects: 7\n",
      "17\n",
      "train loss: nan Acc: 0.4118 | Images trained on: 17\n",
      "Running loss: nan | Running corrects: 0\n",
      "1\n",
      "val loss: nan Acc: 0.0000 | Images trained on: 1\n",
      "Best Epoch Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-chapel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
